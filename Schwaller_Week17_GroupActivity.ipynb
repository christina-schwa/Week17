{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 17 Group Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Write simple (straightforward) definitions for the following parameters for RandomForestClassifier (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and indicate how they correlate with the precision and recall for the basic diabetes model we built in class. You will need to rerun the model multiple times to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**n_estimators:** Lowering n_estimators reduced all scores (accuracy, precision, recall, and f1). Raising n_estimators also reduced all scores. 200 may be the optimal number of estimators because the further we moved away from 200 (in either direction), the lower the scores got."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**max_depth:** This is the maximum length (in number of branches) from the root node to a leaf. Setting max_depth at 18 or above has no effect on the model, suggesting that 18 was probably the depth without any max depth limit set. Setting max_depth below 14 reduces all scores. Setting max_depth at 15, 16, or 17 increases accuracy and also increases either the weighted or macro average of each of the other three scores. Most scores were the same for all three of these max depths, but the macro average of recall was slightly higher for max_depth=15, which suggests that 15 is the optimal depth for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**min_samples_split:** This specifies the minimum number of samples required to split an internal node. It does not guarantee a minimum number of samples in each leaf, though, because it can arbitraily split samples into two leaves containing different numbers of samples. The default is 2, which is essentially the same as  having no limit. With this model, setting min_samples_split higher than 2 usually decreased some of the scores, but various scores would go back up at different settings, and I could not deduce any patterrn. But at min_samples_leaf=7, either the weighted or macro average of each score increased. And at min_samples_split=11, accuracy, precision, and f1 score all increased relative to the default, with recall remaining the same. Setting this parameter much higher (e.g., 50, 100, 500) substantially reduced all scores.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**min_samples_leaf:** This sets the minimum number of samples *or* the minimum percentage of the training data that a leaf must contain. If it's set as an integer, it indicates minimum number of samples. If it's set as a float (<1), it indicates the percentage of samples that each leaf must contain. The default setting is 1, which is essentially the same as no limit. Setting this parameter very low (e.g., 0.001) has no effect on any scores, presumably because all leaves already contained at least 0.1% of the training data. Setting min_samples_leaf to 0.002 (0.2%) or above decreases all scores. Setting it higher than 1 decreases all scores, and I did not find a setting that raised any scores. So in this case, the default (1) is the preferred setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**min_weight_fraction_leaf:** This is the minimum weighted fraction of the input samples required to be in each leaf. The default is 0 (i.e., no limit), although I believe each leaf would have to contain *some* percentage of the training data. For this model, anything higher than min_weight_fraction_leaf=0.0016 (0.16%) lowers all scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**max_features:** This is the maximum number of features the algorithm should consider when determining the best split. If the data has many feaatures, it may be too computationally \"expensive\" to look at all features every time a split is made. Similar to min_samples_leaf, if this parameter is set as an integer, it indicates the maximum number of features to consider at each split, but if it's a float, it indicates the maximum percentage of all features to consider. However, there are additional options:\n",
    "\n",
    "* If “auto”, then max_features=sqrt(n_features).\n",
    "* If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n",
    "* If “log2”, then max_features=log2(n_features).\n",
    "\n",
    "The default is all features (i.e., no limit). Setting this parameter to a percentage below 100% reduced all scores. However, there was not a direct negative correlation. Setting it to 0.5 (50%) or below did not reduce the scores as much as setting it to 0.75 (75%). Setting it to 0.3 (30%) gave the same scores as the default.\n",
    "\n",
    "Setting max_features to 1 reduced all scores, but not nearly as  much as I expected. Setting it higher than 8 produced an error message, which makes sense because there are only nine columns in the dataframe, and one of them is the dependent variable, so we can only consider eight of these as features. Setting max_features to 8 reduced thge accuracy score, which I did not expect because it seemed like max_feaatures=8 would be the same as not setting a limit. Setting max_features as an integer below 8 usually reduced most scores, except at 2 it produced the same scores as the default, and at at 7 it slightly increased f1 score, with accuracy and recall unchanged from the default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**max_leaf_nodes:** This sets a maximum total number of leaves in a decision tree. The default is none (no limit). Anything higher than the default (e.g., 1, 100, 10,000) seems to lower recall and f1 score, and most settings also reduced accuracy and precision, but to a lesser extent. The one exxception I found was that max_leaf_nodes=2 slightly increased the macro average for precision, although it also slightly decreased the weighted average. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**min_impurity_decrease:** This controls how deep the decision tree can go based on its impurity. Setting  the min_impurity_decrease prevents nodes from continuing to split if the impurity does not decrease by the amount specified. Almost any setting other than the default (0) reduced all scores, but setting min_impurity_decrease to a very low float (e.g., 0.00001) slightly increased accuracy, precision (weighted avg. only), and f1 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**min_impurity_split:** This seems to be similar to min_impurity_decrease, but it tells the tree when to stop splitting nodes based on impurity decrease. So it relates to splitting rather than depth. If you run it, it tells you to run min_impurity_decrease instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. How does setting bootstrap=False influence the model performance? Note: the default is bootstrap=True. Explain why your results might be so. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting bootstrap=False slightly lowered all scores (accuracy, precision, recall, and f1). This makes sense because the traditional approach makes many inferences based on one set of samples from the data set, whereas the bootstrapping method keeps resampling from the same set of data, which simulates a larger sample size without increasing impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
